# evadb-artist-preference-prediction

### Project Overview
Our streaming services are a gold mine for meaningful data, at least in my opinion. As you listen to music on a streaming platform, they record the artists you listen to, when you listen, for how long, how many times you replay the track, whether or not you downloaded the music, and so much more. While this may seem unsettling at first, I’ve come to realize that this data is an opportunity for you to learn about what your listening habits say about you, and potentially connect you with other artists and songs you may enjoy. It could even help connect you with other people who enjoy the same music. For my project, I propose that we explore how EvaDB can be used to identify patterns in our streaming data, and use it to make meaningful suggestions and conclusions. 

I originally proposed a wide subset of capabilities to explore, however this became an unfeasible amount of work due to a few limitations imposed by EvaDB. Instead, I decided to narrow the scope of my project and focus on analyzing the sentiment of users’ frequently streamed content and predicting which artists the user will prefer based on their listening habits. These features provide great insights for various stakeholders in the music industry as it allows them to better connect their users with other content on their platform or even with third-party advertisements.

### Implementation Details
First, I set up my work environment. I used Google Colaboratory to create a Jupyter Notebook for the project, which provided an interactive environment to both develop and display the functionality of my tool (for free!). To facilitate the application data, I then installed PostgreSQL, a database management system, into my virtual environment. I also imported EvaDB into the environment to extend AI capabilities into my database. 

Next, I needed to create the supporting data and structures for the tool. So, I started with acquiring a copy of my actual listening data from Apple Music and modifying it with additional attributes that would best train the AI models. Once I formatted my data to my standard, I stored them in the Colab workspace and later imported them into my Postgres database. In the end, I created tables for the songs I most frequently listened to, the artists and genres I most frequently listened to, and a set of artists that weren’t included in my top artists table (these were to be used to test the prediction capabilities of the AI model).

Once I had the foundation built, I focused on integrating the OpenAI models into my PostgreSQL database to achieve the primary functionality. First, I trained a Ludwig AI model to predict whether or not a user would prefer to listen to a new artist. To do this, I passed on data about each artist’s age, genre, peak era, and preference status and turned the trained model into a function using EvaDB. I then tested the validity of the model against the provided preferences of my data set. Once seeing its accuracy, I deployed the model on a new set of artists (unincluded in the data set used for training the model. Before evaluating the compatibility of each candidate with the projects, I first used ChatGPT to pick 3 skills from the taxonomy that were most critical to the project. Using the responses as variables in a different ChatGPT prompt, I was able to evaluate each candidate skill set against the required project skills (as told by ChatGPT) to determine how qualified they were for the project. 

	To achieve the sentiment analysis feature, I simply created a ChatGPT prompt that ran on each of the user’s most listened to songs and used its prior knowledge to evaluate the sentiment of each track using a likert-scale model to measure the positivity of the song with a numerical rating.
